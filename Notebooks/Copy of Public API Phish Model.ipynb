{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1IYmGGHIwkCg6GSc-FggUUIpiQReZc9LB","timestamp":1713803947654}],"authorship_tag":"ABX9TyOQ755esWPuK8VLxLFid2sa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Public Phishing URL Detection model API**\n","\n","*Final project of Machine Learning & Cybersecurity*"],"metadata":{"id":"jaOIR8Dvq3PO"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUnS5xHy8NH7","executionInfo":{"status":"ok","timestamp":1713802584448,"user_tz":-330,"elapsed":116116,"user":{"displayName":"Sayon Kar","userId":"02832033948643167279"}},"outputId":"f735d0fa-56d3-409f-d558-d44c234dd2e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (0.110.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.7.0)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi) (0.37.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.11.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.18.1)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.0)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.29.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n","Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (4.11.0)\n","Collecting pickle5\n","  Using cached pickle5-0.0.11.tar.gz (132 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: pickle5\n","  Building wheel for pickle5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pickle5: filename=pickle5-0.0.11-cp310-cp310-linux_x86_64.whl size=255320 sha256=2591b0aca766d2ce719d97a90c6fa9caf7812bec17bf34fcda1622dd45d1d16f\n","  Stored in directory: /root/.cache/pip/wheels/7d/14/ef/4aab19d27fa8e58772be5c71c16add0426acf9e1f64353235c\n","Successfully built pickle5\n","Installing collected packages: pickle5\n","Successfully installed pickle5-0.0.11\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.7.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.18.1)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.11.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n","Requirement already satisfied: pypi-json in /usr/local/lib/python3.10/dist-packages (0.4.0)\n","Requirement already satisfied: apeye>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (1.4.1)\n","Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (24.0)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from pypi-json) (2.31.0)\n","Requirement already satisfied: apeye-core>=1.0.0b2 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (1.1.5)\n","Requirement already satisfied: domdf-python-tools>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (3.8.0.post2)\n","Requirement already satisfied: platformdirs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from apeye>=1.1.0->pypi-json) (4.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->pypi-json) (2024.2.2)\n","Requirement already satisfied: natsort>=7.0.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (8.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from domdf-python-tools>=2.6.0->apeye>=1.1.0->pypi-json) (4.11.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.3)\n","Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n","Requirement already satisfied: python-whois in /usr/local/lib/python3.10/dist-packages (0.9.3)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from python-whois) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->python-whois) (1.16.0)\n","Requirement already satisfied: sockets in /usr/local/lib/python3.10/dist-packages (1.0.0)\n","Requirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (5.1.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.7)\n","Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.31.0)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract) (2.0.0)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract) (3.13.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.1.0->tldextract) (2024.2.2)\n","Requirement already satisfied: tld in /usr/local/lib/python3.10/dist-packages (0.13)\n"]}],"source":["!pip install fastapi\n","!pip install uvicorn\n","!pip install pickle5\n","!pip install pydantic\n","!pip install scikit-learn\n","!pip install requests\n","!pip install pypi-json\n","!pip install pyngrok\n","!pip install nest-asyncio\n","!pip install pymongo\n","!pip install python-dotenv\n","!pip install python-whois\n","!pip install sockets\n","!pip install tldextract\n","!pip install tld"]},{"cell_type":"code","source":["from fastapi import FastAPI\n","from pydantic import BaseModel\n","import pickle\n","import json\n","import uvicorn\n","from pyngrok import ngrok\n","from fastapi.middleware.cors import CORSMiddleware\n","import nest_asyncio\n","import datetime\n","import ipaddress\n","import re\n","from googlesearch import search\n","import requests\n","import whois\n","import ssl\n","import socket\n","import urllib.parse\n","import tldextract\n","import numpy as np\n","import os\n","from tld import get_tld\n","from urllib.parse import urlparse"],"metadata":{"id":"KE0pNNBX9u5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_url_length(url):\n","    return len(url)\n","\n","def get_domain_length(url):\n","    parsed_url = urlparse(url)\n","    domain = parsed_url.netloc\n","    domain_length = len(domain)\n","    return domain_length\n","\n","def is_domain_ip(url):\n","    try:\n","        parsed_url = urlparse(url)\n","        domain = parsed_url.netloc  # Extract the domain part from the URL\n","        ipaddress.ip_address(domain)  # Check if the domain is a valid IP address\n","        return 1\n","    except ValueError:\n","        return 0\n","\n","def tld_length(tld):\n","    if tld:\n","        return len(tld)\n","    else:\n","        return -1\n","\n","def char_continuation_rate(url):\n","    continuous_count = 0\n","    total_count = len(url)\n","\n","    for i in range(1, len(url)):\n","        if url[i] == url[i - 1]:\n","            continuous_count += 1\n","\n","    if total_count > 0:\n","        continuation_rate = continuous_count / total_count\n","    else:\n","        continuation_rate = 0.0\n","\n","    return continuation_rate\n","\n","def url_character_prob(url):\n","    char_count = {}\n","    total_chars = len(url)\n","\n","    for char in url:\n","        char_count[char] = char_count.get(char, 0) + 1\n","\n","    char_prob = {char: count / total_chars for char, count in char_count.items()}\n","\n","    # Calculate the mean probability\n","    mean_prob = sum(char_prob.values()) / len(char_prob)\n","\n","    return mean_prob\n","\n","def number_of_subdomains(url):\n","    parsed_url = urlparse(url)\n","    domain = parsed_url.netloc\n","\n","    if domain:\n","        num_subdomains = domain.count('.')\n","    else:\n","        num_subdomains = 0\n","\n","    return num_subdomains\n","\n","def has_obfuscation(url):\n","    # List of common obfuscation patterns to detect\n","    obfuscation_patterns = [\n","        '%',                     # Percentage encoding\n","        '\\\\x',                   # Hexadecimal encoding\n","        '&#',                    # HTML entity encoding\n","        '\\\\u',                   # Unicode encoding (corrected)\n","        'javascript:',           # JavaScript code injection\n","        'data:',                 # Data URL scheme\n","        'blob:',                 # Blob URL scheme\n","        'onerror', 'onload',     # Event handlers\n","        'document.cookie',       # Access to cookies\n","        'eval(', 'exec(',        # Evaluation functions\n","        'unescape(',             # Unescaping\n","        'String.fromCharCode(', # Constructing strings\n","        'String.fromCodePoint(', # Constructing strings\n","        'String.raw(',           # Constructing strings\n","    ]\n","\n","    # Check if any obfuscation pattern is found in the URL\n","    for pattern in obfuscation_patterns:\n","        if pattern in url.lower():\n","            return 1  # Obfuscation detected\n","\n","    return 0  # No obfuscation detected\n","\n","def number_of_obfuscated_chars(url):\n","    # List of common obfuscation patterns to detect\n","    obfuscation_patterns = [\n","        '%',     # Percentage encoding\n","        '&#',    # HTML entity encoding\n","        '\\\\u',   # Unicode encoding\n","        '\\\\x',   # Hexadecimal encoding\n","        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n","    ]\n","\n","    # Initialize the counter for obfuscated characters\n","    num_obfuscated_chars = 0\n","\n","    # Check for each obfuscation pattern in the URL\n","    for pattern in obfuscation_patterns:\n","        # Count the occurrences of the obfuscation pattern in the URL\n","        num_obfuscated_chars += url.lower().count(pattern)\n","\n","    return num_obfuscated_chars\n","\n","def obfuscation_ratio(url):\n","    # List of common obfuscation patterns to detect\n","    obfuscation_patterns = [\n","        '%',     # Percentage encoding\n","        '&#',    # HTML entity encoding\n","        '\\\\u',   # Unicode encoding\n","        '\\\\x',   # Hexadecimal encoding\n","        '\\u202E', '\\u200E', '\\u200F', '\\u202A', '\\u202B', '\\u202C'  # Directional formatting characters\n","    ]\n","\n","    # Count the total number of characters in the URL\n","    total_chars = len(url)\n","\n","    # Initialize the counter for obfuscated characters\n","    num_obfuscated_chars = 0\n","\n","    # Check for each obfuscation pattern in the URL\n","    for pattern in obfuscation_patterns:\n","        # Count the occurrences of the obfuscation pattern in the URL\n","        num_obfuscated_chars += url.lower().count(pattern)\n","\n","    # Calculate the obfuscation ratio\n","    obfuscation_ratio = num_obfuscated_chars / total_chars if total_chars > 0 else 0.0\n","\n","    return obfuscation_ratio\n","\n","def number_of_letters_in_url(url):\n","    letters = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ'\n","\n","    num_letters = sum(url.count(letter) for letter in letters)\n","\n","    return num_letters\n","\n","def letter_ratio_in_url(url):\n","    num_letters = number_of_letters_in_url(url)\n","\n","    total_chars = len(url)\n","\n","    if total_chars > 0:\n","        letter_ratio = num_letters / total_chars\n","    else:\n","        letter_ratio = 0.0\n","\n","    return letter_ratio\n","\n","def number_of_digits_in_url(url):\n","    digits = '0123456789'\n","\n","    num_digits = sum(url.count(digit) for digit in digits)\n","\n","    return num_digits\n","\n","def digit_ratio_in_url(url):\n","    num_digits = number_of_digits_in_url(url)\n","\n","    total_chars = len(url)\n","\n","    if total_chars > 0:\n","        digit_ratio = num_digits / total_chars\n","    else:\n","        digit_ratio = 0.0\n","\n","    return digit_ratio\n","\n","def number_of_ampersand_in_url(url):\n","    num_ampersand = url.count('&')\n","\n","    return num_ampersand\n","\n","def number_of_other_special_chars_in_url(url):\n","    allowed_chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789./:?&=%'\n","\n","    num_other_special_chars = sum(1 for char in url if char not in allowed_chars)\n","\n","    return num_other_special_chars\n","\n","def special_char_ratio_in_url(url):\n","    num_special_chars = number_of_other_special_chars_in_url(url)\n","\n","    total_chars = len(url)\n","\n","    if total_chars > 0:\n","        special_char_ratio = num_special_chars / total_chars\n","    else:\n","        special_char_ratio = 0.0\n","\n","    return special_char_ratio\n","\n","def is_https(url):\n","    # Check if the URL starts with \"https://\"\n","    if url.startswith(\"https://\"):\n","        return 1\n","    else:\n","        return 0\n","\n","def calculate_tld_legitimate_prop(url):\n","    try:\n","        # Get the Top-Level Domain (TLD) from the URL\n","        tld = get_tld(url, fail_silently=True)\n","\n","        # List of commonly recognized TLDs used by legitimate websites\n","        legitimate_tlds = ['com', 'net', 'org', 'edu', 'gov']\n","\n","        # Check if the extracted TLD is in the list of legitimate TLDs\n","        if tld in legitimate_tlds:\n","            return 1.0  # TLD is considered legitimate\n","        else:\n","            return 0.0  # TLD is not considered legitimate\n","    except:\n","        return -1  # Error: Unable to extract TLD\n","\n","#Use of IP or not in domain\n","def having_ip_address(url):\n","    match = re.search(\n","        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n","        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\/)|'  # IPv4\n","        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\/)' # IPv4 in hexadecimal\n","        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n","    if match:\n","        # print match.group()\n","        return 1\n","    else:\n","        # print 'No matching pattern found'\n","        return 0\n","\n","def abnormal_url(url):\n","    hostname = urlparse(url).hostname\n","    hostname = str(hostname)\n","    match = re.search(hostname, url)\n","    if match:\n","        # print match.group()\n","        return 1\n","    else:\n","        # print 'No matching pattern found'\n","        return 0\n","\n","def count_per(url):\n","    return url.count('%')\n","\n","def count_ques(url):\n","    return url.count('?')\n","\n","def count_hyphen(url):\n","    return url.count('-')\n","\n","def count_equal(url):\n","    return url.count('=')\n","\n","def count_www(url):\n","  url.count('www')\n","  return url.count('www')\n","\n","def count_atrate(url):\n","  return url.count('@')\n","\n","def no_of_dir(url):\n","  urldir = urlparse(url).path\n","  return urldir.count('/')\n","\n","def no_of_embed(url):\n","  urldir = urlparse(url).path\n","  return urldir.count('//')\n","\n","def count_https(url):\n","    return url.count('https')\n","\n","def count_http(url):\n","    return url.count('http')\n","\n","def count_dot(url):\n","  count_dot = url.count('.')\n","  return count_dot\n","\n","def shortening_service(url):\n","    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n","                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n","                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n","                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n","                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n","                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n","                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n","                      'tr\\.im|link\\.zip\\.net',\n","                      url)\n","    if match:\n","        return 1\n","    else:\n","        return 0\n","\n","def hostname_length(url):\n","    return len(urlparse(url).netloc)\n","\n","def suspicious_words(url):\n","    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n","                      url)\n","    if match:\n","        return 1\n","    else:\n","        return 0\n","\n","def digit_count(url):\n","    digits = 0\n","    for i in url:\n","        if i.isnumeric():\n","            digits = digits + 1\n","    return digits\n","\n","def letter_count(url):\n","    letters = 0\n","    for i in url:\n","        if i.isalpha():\n","            letters = letters + 1\n","    return letters\n","\n","def google_index(url):\n","  site = search(url, 5)\n","  return 1 if site else 0\n","\n","def fd_length(url):\n","    urlpath= urlparse(url).path\n","    try:\n","        return len(urlpath.split('/')[1])\n","    except:\n","        return 0\n","\n","# Request functions\n","\n","# Function to check if the URL is accessible\n","def check_url_access(url):\n","    try:\n","        response = requests.get(url)\n","        return 1  # Return 1 if the URL is accessible\n","    except requests.exceptions.RequestException:\n","        return 0  # Return 0 if there's an error accessing the URL\n","\n","# Function to check if the URL is redirected\n","def check_redirect(url):\n","    try:\n","        response = requests.get(url, allow_redirects=False)\n","        if response.status_code == 301 or response.status_code == 302:\n","            return 0  # Return 0 if the URL is redirected\n","        else:\n","            return 1  # Return 1 if the URL is not redirected\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error accessing {url}: {e}\")\n","        return None\n","\n","# Function to send an HTTP request to the given URL and retrieve the response\n","def send_http_request(url):\n","    try:\n","        response = requests.get(url, timeout=10)  # Set a timeout for the request\n","        if response.status_code == 200:\n","            return 1 if not analyze_content(response) else 0\n","        else:\n","            print(f\"Error accessing {url}: Status code {response.status_code}\")\n","            return None\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error accessing {url}: {e}\")\n","        return None\n","\n","# Function to analyze the content of the response for phishing indicators\n","def analyze_content(url):\n","    try:\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            content = response.text\n","            # Implement content analysis logic here\n","            # Example: Check for presence of known phishing keywords or patterns\n","            phishing_keywords = ['login', 'password', 'bank', 'secure']\n","            for keyword in phishing_keywords:\n","                if re.search(keyword, content, re.IGNORECASE):\n","                    return 0  # Phishing indicator found\n","            return 1  # No phishing indicator found\n","        else:\n","            print(f\"Error: Unable to fetch content from {url}. Status code: {response.status_code}\")\n","            return None\n","    except Exception as e:\n","        print(f\"Error analyzing content for {url}: {e}\")\n","        return None\n","\n","def verify_ssl_certificate(url):\n","    try:\n","        context = ssl.create_default_context()\n","        with socket.create_connection((url, 443)) as sock:\n","            with context.wrap_socket(sock, server_hostname=url) as ssock:\n","                cert = ssock.getpeercert()\n","                if cert:\n","                    # Check if the certificate is valid and issued by a trusted CA\n","                    if ssl.match_hostname(cert, url):\n","                        # Check if the certificate is not expired\n","                        cert_not_after = datetime.datetime.strptime(cert['notAfter'], \"%b %d %H:%M:%S %Y %Z\")\n","                        if cert_not_after > datetime.datetime.now():\n","                            return 1  # Valid SSL certificate\n","                        else:\n","                            return 0  # Expired SSL certificate\n","                    else:\n","                        return 0  # Certificate does not match hostname\n","                else:\n","                    return 0  # No certificate available\n","    except Exception as e:\n","        print(f\"Error verifying SSL certificate for {url}: {e}\")\n","        return None  # Error occurred\n","\n","def query_whois(url):\n","    try:\n","        # Extract domain from the URL\n","        parsed_url = urlparse(url)\n","        domain = parsed_url.netloc\n","\n","        # Perform WHOIS query for the extracted domain\n","        w = whois.whois(domain)\n","\n","        if w:\n","            # Check if WHOIS information indicates the domain is legitimate\n","            # Note: WHOIS information alone might not be sufficient for a definitive conclusion\n","            if 'creation_date' in w and 'expiration_date' in w:\n","                return 1  # Legitimate domain\n","            else:\n","                return 0  # Suspicious domain\n","        else:\n","            return 0  # Suspicious domain\n","    except Exception as e:\n","        # Handle any errors that occur during the WHOIS query\n","        print(f\"Error querying WHOIS information for {domain}: {e}\")\n","        return 0  # Suspicious domain due to error\n","\n","def check_domain_reputation(url):\n","    # Extract domain from the URL\n","    parsed_url = urlparse(url)\n","    domain = parsed_url.netloc\n","\n","    # Example: Using a hypothetical API for domain reputation check\n","    api_url = \"https://example.com/domain-reputation-api\"\n","    payload = {'domain': domain}\n","\n","    try:\n","        response = requests.get(api_url, params=payload)\n","        if response.status_code == 200:\n","            result = response.json()\n","            if result['blacklisted']:\n","                return 0  # Domain is blacklisted\n","            else:\n","                return 1  # Domain is not blacklisted\n","        else:\n","            # API request failed, return an error code or handle the error as needed\n","            return -1  # Error occurred\n","    except Exception as e:\n","        # Handle exceptions such as network errors\n","        print(\"Exception occurred:\", e)\n","        return -1  # Error occurred\n","\n","def check_url_blacklist(url):\n","    # Example: Using a hypothetical API for URL blacklist check\n","    api_url = \"https://example.com/blacklist-api\"\n","    payload = {'url': url}\n","    try:\n","        response = requests.get(api_url, params=payload)\n","        if response.status_code == 200:\n","            result = response.json()\n","            if result['blacklisted']:\n","                return 0  # Phishing URL\n","            else:\n","                return 1  # Safe URL\n","        else:\n","            # API request failed, return an error code or handle the error as needed\n","            return -1  # Error occurred\n","    except Exception as e:\n","        # Handle exceptions such as network errors\n","        print(\"Exception occurred:\", e)\n","        return -1  # Error occurred\n","\n","# Function to analyze the IP address associated with the URL\n","def analyze_ip_address(url):\n","    try:\n","        # Extract domain from the URL\n","        domain = urllib.parse.urlparse(url).netloc\n","\n","        # Get the IP address associated with the domain\n","        ip_address = socket.gethostbyname(domain)\n","\n","        # Check the IP address against threat intelligence sources\n","        if check_blacklist(ip_address):\n","            return 1  # Malicious IP address\n","        else:\n","            return 0  # Clean IP address\n","    except Exception as e:\n","        print(f\"Error analyzing IP address for {url}: {e}\")\n","        return None\n","\n","def check_blacklist(ip_address):\n","    # Example: Check against a public blacklist\n","    blacklist_url = f\"https://www.abuseipdb.com/check/{ip_address}\"\n","    try:\n","        response = requests.get(blacklist_url)\n","        if response.status_code == 200:\n","            # Check if the IP address is listed in the blacklist\n","            if \"This IP address has been reported\" in response.text:\n","                return True\n","            else:\n","                return False\n","        else:\n","            print(f\"Error checking blacklist for {ip_address}: Status code {response.status_code}\")\n","            return False\n","    except Exception as e:\n","        print(f\"Error checking blacklist for {ip_address}: {e}\")\n","        return False\n","\n","# Function to handle different user-agent strings to evade detection\n","def spoof_user_agent(url):\n","    try:\n","        custom_user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.9999.99 Safari/537.36\"\n","        headers = {\n","            'User-Agent': custom_user_agent\n","        }\n","        response = requests.get(url, headers=headers, timeout=10)  # Set a timeout for the request\n","        if response.status_code == 200:\n","            return 1 if not analyze_content(response) else 0\n","        else:\n","            print(f\"Error accessing {url}: Status code {response.status_code}\")\n","            return None\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error accessing {url}: {e}\")\n","        return None\n","\n","# Function to handle sessions and cookies\n","def handle_sessions(url):\n","    session = requests.Session()\n","    try:\n","        response = session.get(url, timeout=10)  # Set a timeout for the request\n","        if response.status_code == 200:\n","            return 1 if not analyze_content(response) else 0\n","        else:\n","            print(f\"Error accessing {url}: Status code {response.status_code}\")\n","            return None\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error accessing {url}: {e}\")\n","        return None\n","\n","# Function to handle request timeouts\n","def handle_request_timeout(url, timeout=5):\n","    try:\n","        response = requests.get(url, timeout=timeout)\n","        if response.status_code == 200:\n","            return 1 if not analyze_content(response) else 0\n","        else:\n","            print(f\"Error accessing {url}: Status code {response.status_code}\")\n","            return None\n","    except requests.exceptions.Timeout:\n","        print(f\"Timeout accessing {url}\")\n","        return 0  # Treat as clean (no phishing indicators) due to timeout\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Error accessing {url}: {e}\")\n","        return None\n","\n","# Function to perform more advanced checks based on TLD and subdomain\n","def advanced_url_analysis(url):\n","    try:\n","        # Extract domain and subdomain information from the URL\n","        extracted = tldextract.extract(url)\n","        domain = extracted.domain\n","        subdomain = extracted.subdomain\n","\n","        # Check if the domain or subdomain contains known malicious patterns\n","        if check_malicious_pattern(domain) or check_malicious_pattern(subdomain):\n","            return 0  # Phishing indicator found\n","        else:\n","            # Query WHOIS information for the domain\n","            if query_whois(domain):\n","                return 1  # Legitimate domain\n","            else:\n","                return 0  # Phishing indicator found\n","    except Exception as e:\n","        print(f\"Error performing advanced URL analysis for {url}: {e}\")\n","        return None\n","\n","def check_malicious_pattern(text):\n","    # Implement logic to check for known malicious patterns in text\n","    malicious_patterns = ['paypal', 'security', 'login', 'bank', 'phish']\n","    for pattern in malicious_patterns:\n","        if pattern in text.lower():\n","            return True\n","    return False\n","\n","def query_whois(domain):\n","    try:\n","        w = whois.whois(domain)\n","        if w:\n","            # Check if WHOIS information indicates the domain is legitimate\n","            if 'creation_date' in w and 'expiration_date' in w:\n","                return True\n","            else:\n","                return False\n","        else:\n","            return False\n","    except Exception as e:\n","        print(f\"Error querying WHOIS information for {domain}: {e}\")\n","        return False\n","\n","def get_main_website_url(long_url):\n","    # Parse the URL to extract its components\n","    parsed_url = urlparse(long_url)\n","\n","    # Construct the main website URL\n","    main_website_url = f\"{parsed_url.scheme}://{parsed_url.netloc}/\"\n","\n","    return main_website_url\n","\n","def mainly(url):\n","\n","    status = []\n","\n","    status.append(get_url_length(url))\n","    status.append(get_domain_length(url))\n","    status.append(is_domain_ip(url))\n","    tld = get_tld(url,fail_silently=True)\n","    status.append(tld_length(tld))\n","    status.append(char_continuation_rate(url))\n","    status.append(url_character_prob(url))\n","    status.append(number_of_subdomains(url))\n","    status.append(has_obfuscation(url))\n","    status.append(number_of_obfuscated_chars(url))\n","    status.append(obfuscation_ratio(url))\n","    status.append(number_of_letters_in_url(url))\n","    status.append(letter_ratio_in_url(url))\n","    status.append(number_of_digits_in_url(url))\n","    status.append(digit_ratio_in_url(url))\n","    status.append(number_of_ampersand_in_url(url))\n","    status.append(number_of_other_special_chars_in_url(url))\n","    status.append(special_char_ratio_in_url(url))\n","    status.append(is_https(url))\n","    status.append(calculate_tld_legitimate_prop(url))\n","    status.append(having_ip_address(url))\n","    status.append(abnormal_url(url))\n","    status.append(count_per(url))\n","    status.append(count_ques(url))\n","    status.append(count_hyphen(url))\n","    status.append(count_equal(url))\n","    status.append(count_www(url))\n","    status.append(count_atrate(url))\n","    status.append(no_of_dir(url))\n","    status.append(no_of_embed(url))\n","    status.append(count_https(url))\n","    status.append(count_dot(url))\n","    status.append(count_http(url))\n","    status.append(shortening_service(url))\n","    status.append(hostname_length(url))\n","    status.append(suspicious_words(url))\n","    status.append(digit_count(url))\n","    status.append(letter_count(url))\n","    status.append(google_index(url))\n","    status.append(fd_length(url))\n","\n","    return status\n","\n","def get_prediction_from_url(test_url):\n","\n","    if(check_url_access(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(check_url_blacklist(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(verify_ssl_certificate(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(send_http_request(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(check_domain_reputation(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(spoof_user_agent(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(handle_sessions(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    if(handle_request_timeout(test_url, timeout=5) == 0):\n","        return \"PHISHING\"\n","\n","    if(advanced_url_analysis(test_url) == 0):\n","        return \"PHISHING\"\n","\n","    #if(analyze_ip_address(test_url) == 0):\n","        #return \"PHISHING\"\n","\n","    #if(query_whois(test_url) == 0):\n","        #return \"PHISHING\"\n","\n","    #if(analyze_content(test_url) == 0):\n","        #return \"PHISHING\"\n","\n","    test_url = get_main_website_url(test_url)\n","\n","    features_test = mainly(test_url)\n","\n","    # Due to updates to scikit-learn, we now need a 2D array as a parameter to the predict function.\n","    features_test = np.array(features_test).reshape((1, -1))\n","\n","    pred = loaded_model.predict(features_test)\n","\n","    return pred"],"metadata":{"id":"Z5A2tDL0Buo8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["app = FastAPI()"],"metadata":{"id":"t9Uqoplr-ES3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["origins = [\"*\"]\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=origins,\n","    allow_credentials=True,\n","    allow_methods=[\"*\"],\n","    allow_headers=[\"*\"],\n",")"],"metadata":{"id":"BQCwDg5M-GYk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class model_input(BaseModel):\n","    url : str"],"metadata":{"id":"m4_isbg1-LoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import os\n","\n","from pymongo import MongoClient\n","# from dotenv import load_dotenv\n","\n","# load_dotenv(\".env\")\n","\n","MONGO_URI = \"mongodb+srv://sayonkar:megacity@phishguard.x6swwrr.mongodb.net/?retryWrites=true&w=majority&appName=PhishGuard\"\n","MONGO_PREDICT_DB = \"dataset\"\n","MONGO_PREDICT_COLLECTION = \"urls\"\n","\n","# Connect to MongoDB\n","try:\n","    client = MongoClient(MONGO_URI)\n","    db = client[MONGO_PREDICT_DB]\n","    collection = db[MONGO_PREDICT_COLLECTION]\n","    connection_status = True\n","except Exception as e:\n","    connection_status = False\n","\n","# Function to check if URL exists in the database and return its type\n","def check_url_type(url):\n","    if not connection_status:\n","        return False\n","\n","    result = collection.find_one({\"url\": url})\n","    if result:\n","        return result[\"type\"]\n","    else:\n","        return False\n","\n","def add_url_to_database(url, url_type):\n","    if not connection_status:\n","        return False\n","\n","    try:\n","        collection.insert_one({\"url\": url, \"type\": url_type})\n","        return True\n","    except Exception as e:\n","        return False"],"metadata":{"id":"YjtwemIBAocg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading the saved model\n","loaded_model = pickle.load(open('trained_model.sav','rb'))"],"metadata":{"id":"TxPT5r75-fap"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@app.post('/url_prediction')\n","def url_pred(input_parameters : model_input):\n","    input_data = input_parameters.json()\n","    input_dictionary = json.loads(input_data)\n","\n","    url = input_dictionary['url']\n","\n","    input_list = [url]\n","\n","    url_type = check_url_type(url)\n","    if url_type:\n","        return f\"'{url_type}'\"\n","    else:\n","        prediction = get_prediction_from_url(url)\n","\n","        if prediction[0] == 0:\n","            diagnosis = \"SAFE\"\n","\n","        elif prediction[0] == 1:\n","            diagnosis = \"PHISHING\"\n","\n","        # Add URL and its type to the database\n","        if add_url_to_database(url, diagnosis):\n","            return diagnosis\n","        else:\n","            return \"Failure\""],"metadata":{"id":"cBwGCNRx_KO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ngrok authtoken 2fRwWS2qV8fmdyBPkzohLCdwBXt_6xSeFsiPkbrwJF5Z938ur"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzprK7q5GNLA","executionInfo":{"status":"ok","timestamp":1713802588212,"user_tz":-330,"elapsed":705,"user":{"displayName":"Sayon Kar","userId":"02832033948643167279"}},"outputId":"bae0b44c-bd84-4228-b708-ba6b212f7957"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"]}]},{"cell_type":"code","source":["ngrok_tunnel = ngrok.connect(8000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","nest_asyncio.apply()\n","uvicorn.run(app, port=8000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vy-i3x90A63n","outputId":"0943d5d6-461d-4cb5-c58e-f89685435ee9"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Public URL: https://addb-34-86-143-6.ngrok-free.app\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["INFO:     Started server process [3441]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","Error verifying SSL certificate for https://claim-ether.fi/: [Errno -2] Name or service not known\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","Error verifying SSL certificate for https://ether-fi.nl/: [Errno -2] Name or service not known\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","Error verifying SSL certificate for https://stackoverflow.com/: [Errno -2] Name or service not known\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","Error verifying SSL certificate for https://stackoverflow.com/: [Errno -2] Name or service not known\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n","Error analyzing content for <Response [200]>: Failed to parse: <Response [200]>\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 500 Internal Server Error\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["ERROR:    Exception in ASGI application\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 407, in run_asgi\n","    result = await app(  # type: ignore[func-returns-value]\n","  File \"/usr/local/lib/python3.10/dist-packages/uvicorn/middleware/proxy_headers.py\", line 69, in __call__\n","    return await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/applications.py\", line 1054, in __call__\n","    await super().__call__(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/applications.py\", line 123, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 186, in __call__\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/errors.py\", line 164, in __call__\n","    await self.app(scope, receive, _send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 93, in __call__\n","    await self.simple_response(scope, receive, send, request_headers=headers)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/cors.py\", line 148, in simple_response\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/middleware/exceptions.py\", line 65, in __call__\n","    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 756, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 776, in app\n","    await route.handle(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 297, in handle\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 77, in app\n","    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 64, in wrapped_app\n","    raise exc\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n","    await app(scope, receive, sender)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/routing.py\", line 72, in app\n","    response = await func(request)\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 278, in app\n","    raw_response = await run_endpoint_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/fastapi/routing.py\", line 193, in run_endpoint_function\n","    return await run_in_threadpool(dependant.call, **values)\n","  File \"/usr/local/lib/python3.10/dist-packages/starlette/concurrency.py\", line 42, in run_in_threadpool\n","    return await anyio.to_thread.run_sync(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/lib/python3.10/asyncio/futures.py\", line 285, in __await__\n","    yield self  # This tells Task to wait for completion.\n","  File \"/usr/lib/python3.10/asyncio/tasks.py\", line 304, in __wakeup\n","    future.result()\n","  File \"/usr/lib/python3.10/asyncio/futures.py\", line 201, in result\n","    raise self._exception.with_traceback(self._exception_tb)\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"<ipython-input-9-9cfdcf44b082>\", line 23, in url_pred\n","    if add_url_to_database(url, diagnosis):\n","UnboundLocalError: local variable 'diagnosis' referenced before assignment\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n","INFO:     210.212.49.25:0 - \"POST /url_prediction HTTP/1.1\" 200 OK\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"adHMTp5dDCA6"},"execution_count":null,"outputs":[]}]}